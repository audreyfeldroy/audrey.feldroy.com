{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce2a999",
   "metadata": {},
   "source": [
    "# Semantic Search With Sentence Transformers and a Bi-Encoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3563aa0",
   "metadata": {},
   "source": [
    "Here I use sentence transformers and a bi-encoder model to encode my notebooks as embeddings and implement semantic search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b112ce8",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577b5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.utils import *\n",
    "from pathlib import Path\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d96617",
   "metadata": {},
   "source": [
    "## Initialize Bi-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7c743",
   "metadata": {},
   "source": [
    "Here we download a bi-encoder model to use for the precomputed embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43fa4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "bienc_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce1746a",
   "metadata": {},
   "source": [
    "## Get All Notebook Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8782968d",
   "metadata": {},
   "source": [
    "We put each notebook to be searched into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4711ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_paths(): \n",
    "    root = Path() if IN_NOTEBOOK else Path(\"nbs/\")\n",
    "    return L(root.glob(\"*.ipynb\")).sorted(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87e74c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#73) [Path('2025-04-14-Building-Jupyter-Notebook-Search-With-Sentence-Transformers.ipynb'),Path('2025-04-08-Get-a-Jupyter-Notebook-Filename-From-Itself.ipynb'),Path('2025-03-20-Minimal-Screen-Recording-on-macOS-No-Third-Party-Apps-Required.ipynb'),Path('2025-03-14-Pi.ipynb'),Path('2025-02-20-One-Liner-to-Clean-Python-Bytecode.ipynb'),Path('2025-02-15-Building-a-Better-Title-Caser-Part-2-Using-an-Ollama-Modelfile.ipynb'),Path('2025-02-14-Building-a-Better-Title-Caser-Part-1-Beyond-Python-str-title.ipynb'),Path('2025-02-13-Excavating-a-Lost-CLI-Tool.ipynb'),Path('2025-02-12-My-Self-Analysis-of-How-to-Get-Back-to-Posting-Every-Day.ipynb'),Path('2025-02-09-An-Informationally-Dense-Index-Page.ipynb'),Path('2025-02-08-This-Notebook-Is-Also-a-Keylogger.ipynb'),Path('2025-02-07-This-Site-Is-Now-Powered-by-This-Notebook-Part-6.ipynb'),Path('2025-02-06-Creating-an-Accessible-Inline-Nav-FastTag.ipynb'),Path('2025-02-05-Create-a-CLI-Tool-With-Fastcore-Script.ipynb'),Path('2025-02-04-How-to-Turn-a-Jupyter-Notebook-Into-a-Python-Script.ipynb'),Path('2025-02-03-FastHTML-and-MonsterUI-Time-Converter.ipynb'),Path('2025-02-02-Text-Embeddings-and-Cosine-Similarity.ipynb'),Path('2025-02-01-Auto-Renaming-My-Untitled-ipynb-Files-With-Gemini.ipynb'),Path('2025-01-31-Performance-Optimization-Moving-HTML-Class-Injection-from-lxml-to-Mistletoe.ipynb'),Path('2025-01-30-This-Site-Is-Now-Powered-by-This-Notebook-Part-5.ipynb')...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_paths = get_nb_paths()\n",
    "nb_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60bcd3c",
   "metadata": {},
   "source": [
    "## Create an Embedding for Each Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da027d",
   "metadata": {},
   "source": [
    "Now we can turn that list of notebook paths into embeddings by:\n",
    "\n",
    "1. Opening each notebook file\n",
    "2. Putting notebook content into a list of notebooks\n",
    "3. Passing the notebook list to the bi-encoder model to generate a list of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20c3b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nb_simple(nb_path):\n",
    "    with open(nb_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e92b9505",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs = L(nb_paths).map(read_nb_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "429a4338",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_embs = bienc_model.encode(nbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61588c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nb_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ec2867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 384)\n"
     ]
    }
   ],
   "source": [
    "print(nb_embs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ad786",
   "metadata": {},
   "source": [
    "## Encode the Query String"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b089f81",
   "metadata": {},
   "source": [
    "If we search for a particular query string, that string needs to be encoded as an embedding using the same bi-encoder as before. Then we can compare it to the notebook embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e204f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"Web search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e781f73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0328431 , -0.00064043, -0.06456785,  0.01314389, -0.02520958,\n",
       "        0.02097196,  0.03034499,  0.05960393, -0.03566388, -0.03963251],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_emb = bienc_model.encode(q)\n",
    "q_emb[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4445175f",
   "metadata": {},
   "source": [
    "## Create a Cosine Similarities Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb87b23",
   "metadata": {},
   "source": [
    "Sentence Transformers provides a function to get the similarity between the query and each of the notebook embeddings. It defaults to cosine similarity. We use it to get a tensor of how similar the query embedding is to each notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56ba8be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2229, -0.0333, -0.0670,  0.0745,  0.0353,  0.0670,  0.0779,  0.0709,\n",
       "          0.0786,  0.1814,  0.0342,  0.0047,  0.0716,  0.0518, -0.0770,  0.1202,\n",
       "          0.1646,  0.0790,  0.0343,  0.0567,  0.0842,  0.0070,  0.1067,  0.0751,\n",
       "         -0.0592, -0.0341, -0.0082,  0.0048,  0.0697,  0.0034,  0.0660,  0.1866,\n",
       "          0.0680,  0.0811,  0.0612,  0.1918,  0.2615,  0.2304,  0.1414,  0.0626,\n",
       "          0.1566,  0.0056,  0.1292,  0.0197,  0.1162, -0.0663,  0.0835,  0.0663,\n",
       "          0.0659,  0.0946,  0.1104,  0.0101,  0.1370,  0.0635,  0.0044,  0.0777,\n",
       "         -0.0330, -0.0023,  0.0593,  0.0358,  0.0823,  0.0667,  0.0458,  0.1565,\n",
       "          0.1318,  0.1485,  0.1480,  0.0771,  0.0885,  0.0954,  0.0929,  0.0607,\n",
       "          0.1207]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = bienc_model.similarity(q_emb, nb_embs)\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ece71c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 73])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4dff3",
   "metadata": {},
   "source": [
    "## Get Top 10 Similar Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16499e84",
   "metadata": {},
   "source": [
    "Sentence Transformers also provides a semantic search utility that returns search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4cb047e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'corpus_id': 36, 'score': 0.2615070044994354},\n",
       "  {'corpus_id': 37, 'score': 0.2304057776927948},\n",
       "  {'corpus_id': 0, 'score': 0.22291576862335205},\n",
       "  {'corpus_id': 35, 'score': 0.1918058693408966},\n",
       "  {'corpus_id': 31, 'score': 0.18661072850227356},\n",
       "  {'corpus_id': 9, 'score': 0.18138977885246277},\n",
       "  {'corpus_id': 16, 'score': 0.16460278630256653},\n",
       "  {'corpus_id': 40, 'score': 0.15658749639987946},\n",
       "  {'corpus_id': 63, 'score': 0.15653306245803833},\n",
       "  {'corpus_id': 65, 'score': 0.1485363095998764}]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits = util.semantic_search(q_emb, nb_embs, top_k=10)\n",
    "hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf94145",
   "metadata": {},
   "source": [
    "Let's display the search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9fc0e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [{'corpus_id': 36, 'score': 0.2615070044994354},{'corpus_id': 37, 'score': 0.2304057776927948},{'corpus_id': 0, 'score': 0.22291576862335205},{'corpus_id': 35, 'score': 0.1918058693408966},{'corpus_id': 31, 'score': 0.18661072850227356},{'corpus_id': 9, 'score': 0.18138977885246277},{'corpus_id': 16, 'score': 0.16460278630256653},{'corpus_id': 40, 'score': 0.15658749639987946},{'corpus_id': 63, 'score': 0.15653306245803833},{'corpus_id': 65, 'score': 0.1485363095998764}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(hits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80c6db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_search_result(hit): print(f\"{hit['score']:.4f} {nb_paths[hit['corpus_id']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea2e5b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2615 2025-01-14-Constructing-SQLite-Tables-for-Notebooks-and-Search.ipynb\n",
      "0.2304 2025-01-13-SQLite-FTS5-Tokenizers-unicode61-and-ascii.ipynb\n",
      "0.2229 2025-04-14-Building-Jupyter-Notebook-Search-With-Sentence-Transformers.ipynb\n",
      "0.1918 2025-01-16-Cosine-Similarity-Breakdown-in-LaTeX.ipynb\n",
      "0.1866 2025-01-20-Dark-and-Light-Mode-in-FastHTML.ipynb\n",
      "0.1814 2025-02-09-An-Informationally-Dense-Index-Page.ipynb\n",
      "0.1646 2025-02-02-Text-Embeddings-and-Cosine-Similarity.ipynb\n",
      "0.1566 2025-01-10-Understanding-FastHTML-Routes-Requests-and-Redirects.ipynb\n",
      "0.1565 2024-12-23-Daddys_Snowman_Card.ipynb\n",
      "0.1485 2024-08-04-Claudette.ipynb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#10) [None,None,None,None,None,None,None,None,None,None]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(hits[0]).map(print_search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca5117",
   "metadata": {},
   "source": [
    "## Define a Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39125182",
   "metadata": {},
   "source": [
    "Putting together everything we've figured out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8176fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bienc_search_nbs(q):\n",
    "    nb_paths = get_nb_paths()\n",
    "    nbs = L(nb_paths).map(read_nb_simple)\n",
    "    nb_embs = bienc_model.encode(nbs)\n",
    "    q_emb = bienc_model.encode(q)\n",
    "    hits = util.semantic_search(q_emb, nb_embs, top_k=10)\n",
    "    L(hits[0]).map(print_search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4195d95e",
   "metadata": {},
   "source": [
    "We can try out our biencoder-based semantic search function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f7d921d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2891 2025-01-14-Constructing-SQLite-Tables-for-Notebooks-and-Search.ipynb\n",
      "0.2743 2025-04-14-Building-Jupyter-Notebook-Search-With-Sentence-Transformers.ipynb\n",
      "0.2348 2025-01-13-SQLite-FTS5-Tokenizers-unicode61-and-ascii.ipynb\n",
      "0.1928 2024-12-23-Daddys_Snowman_Card.ipynb\n",
      "0.1794 2025-02-02-Text-Embeddings-and-Cosine-Similarity.ipynb\n",
      "0.1778 2025-02-13-Excavating-a-Lost-CLI-Tool.ipynb\n",
      "0.1713 2024-12-24-Trying-execnb.ipynb\n",
      "0.1703 2025-02-09-An-Informationally-Dense-Index-Page.ipynb\n",
      "0.1624 2025-01-12-A-Better-Notebook-Index-Page.ipynb\n",
      "0.1609 2024-07-29-Delegates-Decorator.ipynb\n"
     ]
    }
   ],
   "source": [
    "bienc_search_nbs(\"search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db49820",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa5ea8e",
   "metadata": {},
   "source": [
    "A bi-encoder is nice because it allows you to pregenerate embeddings and later use those for comparison. But it's not as accurate as a cross-encoder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
